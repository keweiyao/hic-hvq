#!/usr/bin/env python3

"""
Runs several complete heavy-ion collision events:

  - initial condition (trento)
  - free streaming
  - hydro (vishnew)
  - particlization / sampler (frzout)
  - hadronic afterburner (urqmd)

If an argument is passed, it is read as a configuration file with simple
key = value syntax and stored in the 'config' dict.  Values are then accessed
with 'config.get()' and hence all have reasonable defaults.

For each event, computes observables (multiplicities, mean transverse momenta,
flow vectors, etc) and saves them in raw binary file 'results', which may be
read by np.fromfile() using the same dtype as the 'results' array.

Some advantages of this format:

  - speed and file size (zero overhead)
  - files may be concatened together
  - easy I/O in numpy (fromfile/tofile)

A disadvantage:

  - no metadata is saved, so the precise data type must be known and fully
	specified or the files are nonsense

"""

from itertools import chain
import sys
import subprocess

import numpy as np
import h5py

import freestream
import frzout

from scipy.interpolate import interp1d


def run_cmd(*args, **kwargs):
	"""
	Run a subprocess, concatenating argument strings together.

	"""
	print(*args, flush=True)  # flush stdout to retain output order
	subprocess.check_call(
		list(chain.from_iterable(a.split() for a in args)),
		**kwargs
	)


def read_text_file(filename):
	"""
	Read a text file into a nested list of bytes objects,
	skipping comment lines (#).

	"""
	with open(filename, 'rb') as f:
		return [l.split() for l in f if not l.startswith(b'#')]


def main():
	fresult = h5py.File('results.hdf5','a')
	# parse config file
	if len(sys.argv) >= 2:
		with open(sys.argv[1], 'r') as f:
			config = dict(
				(i.strip() for i in l.split('=', maxsplit=1))
				for l in f if l[0] != '#'
			)
		if len(sys.argv) == 3:
			run_id = int(sys.argv[2])
		else:	
			print("Hi")
			run_id = 0
	else:
		config = {}
	print ('==========',run_id, '=============')
	nevents = 1
	grid_step = 0.1
	grid_max = 13.05

	# run trento and yield initial entropy density arrays
	def initial_conditions(initial_file='initial.hdf'):
		run_cmd(
			'trento Pb Pb', str(nevents),
			'--grid-step {} --grid-max {}'.format(grid_step, grid_max),
			'--output', initial_file,
			config.get('trento_args', '')
		)
		with h5py.File(initial_file, 'r') as f:
			for dset in f.values():
				if dset.name[1:4] != 'TAB':
					yield [np.array(dset), np.array(f['TAB'+dset.name[-2:]])]

	#==================FONLL========================================
	x0, y0 = np.loadtxt('./hic-hvq/share/hvq/PbPb-dX-dpT2-dy.dat').T
	FONLL = interp1d(x0, y0, fill_value='extrapolate')
	
	#==================Hard pT bins=================================
	pTlow = 0.
	pThigh = 50.
	NpT = 50
	pTbins = np.linspace(pTlow, pThigh, NpT+1)
	pTmid = (pTbins[:-1] + pTbins[1:])/2.

	# read free streaming time and enable for time > epsilon
	tau_fs = float(config.get('tau_fs', 0))
	enable_fs = tau_fs > 1e-6

	# create sampler HRG object (to be reused for all events)
	Tswitch = float(config.get('Tswitch', .15))
	hrg = frzout.HRG(Tswitch, species='urqmd', res_width=True)
	eswitch = hrg.energy_density()

	# append switching energy density to vishnew arguments
	vishnew_args = [
		config.get('vishnew_args', ''),
		'initialuread=1 iein=0 t0={}'.format(tau_fs) if enable_fs else
		'initialuread=0 iein=1',
		'edec={}'.format(eswitch)
	]

	# species (name, ID) for identified particle observables
	species = [
		('pion', 211),
		('kaon', 321),
		('proton', 2212),
	]

	# Heavy quark species (name, ID)
	HQ_species = [
		('D0', 421), ('D+', 411),
		('D*+', 10411),
	  #  ('Ds+', 431), ('Ds*+', 433), ('D0*', 10421), 
	]
	HQ_id = [s[1] for s in HQ_species]	

	# fully specify numeric data types, including endianness and size, to
	# ensure consistency across all machines
	float_t = '<f8'
	int_t = '<i8'
	complex_t = '<c16'

	# run each event
	for ievent, ic in enumerate(initial_conditions()):
		event_gp = fresult.create_group('event_{}_{}'.format(run_id, ievent))
		soft_gp = event_gp.create_group('soft')
		hard_gp = event_gp.create_group('hard')
		quark_gp = hard_gp.create_group('quark')
		meson_gp = hard_gp.create_group('meson')
		w_urqmd_qp = meson_gp.create_group('w_urqmd')
		wo_urqmd_qp = meson_gp.create_group('wo_urqmd')
		soft_gp.attrs.create('initial_entropy', grid_step**2 * ic[0].sum())
		hard_gp.attrs.create('T_AB', grid_step**2 * ic[1].sum())
		hard_gp.attrs.create('pT_low', pTlow)
		hard_gp.attrs.create('pT_high', pThigh)
		hard_gp.attrs.create('pT_N', NpT)

		# ==================IC+freestream===========================
		if enable_fs:
			# free stream initial condition
			fs = freestream.FreeStreamer(ic[0], grid_max, tau_fs)

			e = fs.energy_density()
			e_above = e[e > eswitch].sum()
			soft_gp.attrs.create('mult_factor', e.sum()/e_above if e_above > 0 else 1)

			np.savetxt('ed.dat', e)
			for i in [1, 2]:
				np.savetxt('u{}.dat'.format(i), fs.flow_velocity(i))
			for ij in [(1, 1), (1, 2), (2, 2)]:
				np.savetxt(
					'pi{}{}.dat'.format(*ij), fs.shear_tensor(*ij))
		else:
			# skip free streaming, use initial condition as entropy density
			np.savetxt('sd.dat', ic[0])
		# ==================Vishnew===========================
		# hydro
		run_cmd('vishnew', *vishnew_args)
		# ==================Frzout Sampler===========================
		# read freeze-out surface data
		surface_data = np.array(
			read_text_file('surface.dat'),
			dtype=float
		)
		# end event if the surface is empty -- this occurs in ultra-peripheral
		# events where the initial condition doesn't exceed Tswitch
		if surface_data.size == 0:
			print('empty hypersurface')
			continue

		# unpack surface_data columns:
		#   0	1  2  3		 4		 5		 6	7
		#   tau  x  y  dsigma^t  dsigma^x  dsigma^y  v_x  v_y
		#   8	 9	 10	11	12	13	14	15
		#   pitt  pitx  pity  pixx  pixy  piyy  pizz  Pi
		x, sigma, v, _ = np.hsplit(surface_data, [3, 6, 8])
		pi = dict(zip(['xx', 'xy', 'yy'], surface_data.T[11:14]))
		Pi = surface_data.T[15]
		# create sampler surface object
		surface = frzout.Surface(x, sigma, v, pi=pi, Pi=Pi, ymax=4)

		minsamples, maxsamples = 10, 100  # reasonable range for nsamples
		minparts = 10**5  # min number of particles to sample
		nparts = 0  # for tracking total number of sampled particles

		# sample soft particles and write to file
		with open('particles_in.dat', 'w') as f:
			for nsamples in range(1, maxsamples + 1):
				parts = frzout.sample(surface, hrg)
				if parts.size == 0:
					continue
				nparts += parts.size
				print('#', parts.size, file=f)
				for p in parts:
					print(p['ID'], *chain(p['x'], p['p']), file=f)
				if nparts >= minparts and nsamples >= minsamples:
					break

		if nparts == 0:
			print('no particles produced')
			continue

		soft_gp.attrs.create('nsamples', nsamples, dtype=int_t)

		# ==================Heavy Flavor===========================
		run_cmd('run-hvq-events ./JetData.h5 ./initial.hdf {} {}'.format(sys.argv[1], run_id))

		# ==================Heavy + Soft --> UrQMD===========================
		run_cmd('afterburner {} particles_out_{}.dat particles_in.dat h-meson-final-{}.dat'.format(nsamples, run_id, run_id))

		# ==================Data Processing==================================
		# For initial charm
		fcharm = h5py.File('./HeavyFlavorResult.hdf5', 'r')
		charm_ipT = fcharm['quark-pT0-{}'.format(run_id)].value
		charm_weight = charm_ipT*FONLL(charm_ipT)
		quark_gp.attrs.create('Wtot', charm_weight.sum())

		# read final particle data	
		ID, charge, fmass, px, py, pz, y, eta, ipT, iw = (
			np.array(col, dtype=dtype) for (col, dtype) in
			zip(
				zip(*read_text_file('particles_out_{}.dat'.format(run_id))),
				(2*[int] + 8*[float])
			)
		)
		pT = np.sqrt(px**2+py**2)
		phi = np.arctan2(py, px)
		charged = (charge != 0)
		abs_eta = np.fabs(eta)
		abs_ID = np.abs(ID)
		midrapidity = (np.fabs(y) < .5)
		soft_index = [iID not in HQ_id for iID in abs_ID]
			
		# for soft particles
		soft_gp.attrs.create('dNch_deta',
			np.count_nonzero(charged & (abs_eta < .5) & soft_index) / nsamples)
		soft_gp.attrs.create('cen_mult',
			np.count_nonzero(charged & (abs_eta < .8) & soft_index) / nsamples)
		phi_alice = phi[charged & (abs_eta < .8) & (.2 < pT) & (pT < 5.)]
		soft_gp.attrs.create('M', phi_alice.size, dtype=int_t)
		soft_gp.create_dataset('Qn', data=np.array([np.exp(1j*n*phi_alice).sum() for n in range(1, 7)]), dtype=complex_t)

		# for heavy flavor after urqmd
		Raa_eta_cut = (np.fabs(y) < .5)
		v2_eta_cut = (np.fabs(y) < .8)
		for name, isp in HQ_species:
			specie_gp = w_urqmd_qp.create_group(name)
			# calculate pT-spectra
			cut = (abs_ID == isp) & Raa_eta_cut
			HQpT, HQw = pT[cut], ipT[cut]*FONLL(ipT[cut])
			Hist, BinEdges = np.histogram(HQpT, bins=NpT, range=[pTlow, pThigh], normed=True, weights=HQw)
			specie_gp.create_dataset('dN_dpt2_Ntot', data=Hist/pTmid, dtype=float_t) 
			specie_gp.attrs.create('Ntot', HQw.sum(), dtype=float_t)

			# calculate Qn
			cut = (abs_ID == isp) & v2_eta_cut
			HQphi, HQpT, HQw = phi[cut], pT[cut], ipT[cut]*FONLL(ipT[cut])
			Qn_array = np.zeros([NpT, 3], dtype=complex_t)
			M_array = np.zeros(NpT)
			for icut, [pl, ph] in enumerate(zip(pTbins[:-1], pTbins[1:])):
				pTcut = (pl < HQpT) & (HQpT <= ph)
				diff_phi = HQphi[pTcut]
				diff_w = HQw[pTcut]
				Qn_array[icut] = np.array([(np.exp(1j*n*diff_phi)*diff_w).sum() for n in range(1, 4)], dtype=complex_t)
				M_array[icut] = diff_w.sum()
			specie_gp.create_dataset('Qn', data=Qn_array, dtype=complex_t)
			specie_gp.create_dataset('M', data=M_array, dtype=float_t)

	fresult.close()


if __name__ == "__main__":
	main()
