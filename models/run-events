#!/usr/bin/env python3

from itertools import chain
import sys
import subprocess

import numpy as np
import h5py

import freestream
import frzout

from scipy.interpolate import interp1d


def run_cmd(*args, **kwargs):
	"""
	Run a subprocess, concatenating argument strings together.

	"""
	print(*args, flush=True)  # flush stdout to retain output order
	subprocess.check_call(
		list(chain.from_iterable(a.split() for a in args)),
		**kwargs
	)


def read_text_file(filename):
	"""
	Read a text file into a nested list of bytes objects,
	skipping comment lines (#).

	"""
	with open(filename, 'rb') as f:
		return [l.split() for l in f if not l.startswith(b'#')]


def main():
	fresult = h5py.File('results.hdf5','a')
	# parse config file
	if len(sys.argv) >= 2:
		with open(sys.argv[1], 'r') as f:
			config = dict(
				(i.strip() for i in l.split('=', maxsplit=1))
				for l in f if l[0] != '#'
			)
		if len(sys.argv) == 3:
			run_id = int(sys.argv[2])
		else:	
			print("Hi")
			run_id = 0
	else:
		config = {}
	print ('==========',run_id, '=============')
	nevents = 1
	grid_step = 0.1
	grid_max = 15.05

	# run trento and yield initial entropy density arrays
	def initial_conditions(initial_file='initial.hdf'):
		run_cmd(
			'trento Pb Pb', str(nevents),
			'--grid-step {} --grid-max {}'.format(grid_step, grid_max),
			'--output', initial_file,
			config.get('trento_args', '')
		)
		with h5py.File(initial_file, 'r') as f:
			for dset in f.values():
				if dset.name[1:4] != 'TAB':
					yield [np.array(dset), np.array(f['TAB'+dset.name[-2:]])]

	#==================Hard pT bins and exp cuts=================================
	pTlow = 0.
	pThigh = 50.
	NpT = 50
	pTbins = np.linspace(pTlow, pThigh, NpT+1)
	pTmid = (pTbins[:-1] + pTbins[1:])/2.
	exp_name = config.get('collaboration', 'something else')
	sqrts = config.get('sqrts', '2760')
	print ('exp : ', exp_name)
	print ('sqrts :', sqrts, " GeV")
	if exp_name == "CMS":
		print('use CMS cuts')
		exp_Raa_ycut = 1.0
		exp_vn_ycut = 1.0
	elif exp_name == "ALICE":
		print('use ALICE cuts')
		exp_Raa_ycut = 0.5
		exp_vn_ycut = 0.8
	elif exp_name == "STAR":
		exp_Raa_ycut = 1.0
		exp_vn_ycut = 1.0
	else:
		print('use large cuts')
		exp_Raa_ycut = 2.0
		exp_vn_ycut = 2.0
	#==================FONLL========================================
	x0, y0 = np.loadtxt('./hic-hvq/share/hvq/{}GeV/PbPb-dX-dpT2-dy.dat'.format(sqrts)).T
	FONLL = interp1d(x0, y0, fill_value='extrapolate')
	print("Xtot: PbPb-->charm, ", np.sum(x0*y0)*(x0[1]-x0[0]))

	# read free streaming time and enable for time > epsilon
	tau_fs = float(config.get('tau_fs', 0))
	enable_fs = tau_fs > 1e-6

	# create sampler HRG object (to be reused for all events)
	Tswitch = float(config.get('Tswitch', .154))
	hrg = frzout.HRG(Tswitch, species='urqmd', res_width=True)
	eswitch = hrg.energy_density()

	# append switching energy density to vishnew arguments
	vishnew_args = [
		config.get('vishnew_args', ''),
		'initialuread=1 iein=0 t0={}'.format(tau_fs) if enable_fs else
		'initialuread=0 iein=1',
		'edec={}'.format(eswitch)
	]

	# species (name, ID) for identified particle observables
	species = [
		('pion', 211),
		('kaon', 321),
		('proton', 2212),
	]

	# Heavy quark species (name, ID)
	HQ_species = [
		 ('D+', 411), 
		 ('D0', 421),
		 ('D*+', 10411),
		 ('D0*', 10421), 
		 ('Ds+', 431), 
		 ('Ds*+', 433)
	]
	HQ_id = [s[1] for s in HQ_species]	

	# fully specify numeric data types, including endianness and size, to
	# ensure consistency across all machines
	float_t = '<f8'
	int_t = '<i8'
	complex_t = '<c16'

	# run each event
	for ievent, ic in enumerate(initial_conditions()):
		event_gp = fresult.create_group('event_{}_{}'.format(run_id, ievent))
		soft_gp = event_gp.create_group('soft')
		hard_gp = event_gp.create_group('hard')
		quark_gp = hard_gp.create_group('quark')
		meson_gp = hard_gp.create_group('meson')
		w_urqmd_gp = meson_gp.create_group('w_urqmd')
		wo_urqmd_gp = meson_gp.create_group('wo_urqmd')
		soft_gp.attrs.create('initial_entropy', grid_step**2 * ic[0].sum())
		hard_gp.attrs.create('T_AB', grid_step**2 * ic[1].sum())
		hard_gp.attrs.create('pT_low', pTlow)
		hard_gp.attrs.create('pT_high', pThigh)
		hard_gp.attrs.create('pT_N', NpT)

		# ==================IC+freestream===========================
		if enable_fs:
			# free stream initial condition
			fs = freestream.FreeStreamer(ic[0], grid_max, tau_fs)

			e = fs.energy_density()
			e_above = e[e > eswitch].sum()
			soft_gp.attrs.create('mult_factor', e.sum()/e_above if e_above > 0 else 1)

			np.savetxt('ed.dat', e)
			for i in [1, 2]:
				np.savetxt('u{}.dat'.format(i), fs.flow_velocity(i))
			for ij in [(1, 1), (1, 2), (2, 2)]:
				np.savetxt(
					'pi{}{}.dat'.format(*ij), fs.shear_tensor(*ij))
		else:
			# skip free streaming, use initial condition as entropy density
			np.savetxt('sd.dat', ic[0])
		# ==================Vishnew===========================
		# hydro
		run_cmd('vishnew', *vishnew_args)
		# ==================Frzout Sampler===========================
		# read freeze-out surface data
		surface_data = np.array(
			read_text_file('surface.dat'),
			dtype=float
		)
		# end event if the surface is empty -- this occurs in ultra-peripheral
		# events where the initial condition doesn't exceed Tswitch
		if surface_data.size == 0:
			print('empty hypersurface')
			continue

		# unpack surface_data columns:
		#   0	1  2  3		 4		 5		 6	7
		#   tau  x  y  dsigma^t  dsigma^x  dsigma^y  v_x  v_y
		#   8	 9	 10	11	12	13	14	15
		#   pitt  pitx  pity  pixx  pixy  piyy  pizz  Pi
		x, sigma, v, _ = np.hsplit(surface_data, [3, 6, 8])
		pi = dict(zip(['xx', 'xy', 'yy'], surface_data.T[11:14]))
		Pi = surface_data.T[15]
		# create sampler surface object
		surface = frzout.Surface(x, sigma, v, pi=pi, Pi=Pi, ymax=2.)

		minsamples, maxsamples = 10, 100  # reasonable range for nsamples
		minparts = 20000  # min number of particles to sample
		nparts = 0  # for tracking total number of sampled particles

		# sample soft particles and write to file
		with open('particles_in.dat', 'w') as f:
			for nsamples in range(1, maxsamples + 1):
				parts = frzout.sample(surface, hrg)
				if parts.size == 0:
					continue
				nparts += parts.size
				print('#', parts.size, file=f)
				for p in parts:
					print(p['ID'], *chain(p['x'], p['p']), file=f)
				if nparts >= minparts and nsamples >= minsamples:
					break

		if nparts == 0:
			print('no particles produced')
			continue

		soft_gp.attrs.create('nsamples', nsamples, dtype=int_t)

		# ==================Heavy Flavor===========================
		run_cmd('run-hvq-events ./JetData.h5 ./initial.hdf {} {}'.format(sys.argv[1], run_id))

		# ==================Heavy + Soft --> UrQMD===========================
		run_cmd('afterburner {} particles_out_{}.dat particles_in.dat h-meson-final-{}.dat'.format(nsamples, run_id, run_id))

		# ==================Data Processing==================================
		
		# ----Function to calculate Raa and v2-------------------------------
		def get_Raa(pid, pT, y, ipT, yabs_cut, species):
			# calculate pT-spectra for each species
			Raa = {}
			for (Dname, Did) in species:
				cut = (np.abs(y) < yabs_cut) & (pid == Did)
				HQpT, HQw = pT[cut], ipT[cut]*FONLL(ipT[cut])
				Hist, BinEdges = np.histogram(HQpT, bins=NpT, range=[pTlow, pThigh], normed=True, weights=HQw)
				Raa.update({Dname : {'shape' : Hist, 'Ntot' : HQw.sum()} })
			return Raa
		def get_vn(pid, phi, pT, y, ipT, yabs_cut, species):
			# calculate Qn
			vn = {}
			for (Dname, Did) in species:
				cut = (np.abs(y) < yabs_cut) & (pid == Did)
				HQphi, HQpT, HQw = phi[cut], pT[cut], ipT[cut]*FONLL(ipT[cut])
				Qn_array = np.zeros([NpT, 3], dtype=complex_t)
				M_array = np.zeros(NpT)
				for icut, [pl, ph] in enumerate(zip(pTbins[:-1], pTbins[1:])):
					pTcut = (pl < HQpT) & (HQpT <= ph)
					diff_phi = HQphi[pTcut]
					diff_w = HQw[pTcut]
					Qn_array[icut] = np.array([(np.exp(1j*n*diff_phi)*diff_w).sum() for n in range(1, 4)], dtype=complex_t)
					M_array[icut] = diff_w.sum()
				vn.update({Dname : {'Qn' : Qn_array, 'M' : M_array} })
			return vn
				
		# For final charm quark
		fquark = h5py.File('./HeavyFlavorResult.hdf5', 'r')
		ipT = fquark['quark-pT0-{}'.format(run_id)].value
		px, py, pz, E = fquark['quark-pv-{}'.format(run_id)].value.T
		pid = fquark['quark-pid-{}'.format(run_id)].value
		fquark.close()
		y = 0.5*np.log((E+pz)/(E-pz))
		pT = np.sqrt(px**2 + py**2)
		phi = np.arctan2(py, px)
		species = [('charm', 4)]
		
		Raa = get_Raa(pid=pid, pT=pT, y=y, ipT=ipT, yabs_cut=10., species=species)
		vn = get_vn(pid=pid, phi=phi, pT=pT, y=y, ipT=ipT, yabs_cut=10., species=species)
		dndpt_gp = quark_gp.create_group('dN_dpt')
		vn_gp = quark_gp.create_group('vn')
		for (Cname, Cid) in species:
			dn_i_dpt_gp = dndpt_gp.create_group(Cname)
			dn_i_dpt_gp.create_dataset('shape', data=Raa[Cname]['shape'], dtype=float_t)
			dn_i_dpt_gp.attrs.create('Ntot', Raa[Cname]['Ntot']*exp_Raa_ycut/2., dtype=float_t)
			
			vn_i_gp = vn_gp.create_group(Cname)
			vn_i_gp.create_dataset('Qn', data=vn[Cname]['Qn'], dtype=complex_t)
			vn_i_gp.create_dataset('M', data=vn[Cname]['M'], dtype=float_t)

		# for heavy flavor before urqmd
		fmeson = h5py.File('./HeavyFlavorResult.hdf5', 'r')
		ipT = fmeson['meson-pT0-{}'.format(run_id)].value
		px, py, pz, E = fmeson['meson-pv-{}'.format(run_id)].value.T
		pid = fmeson['meson-pid-{}'.format(run_id)].value
		fmeson.close()
		y = 0.5*np.log((E+pz)/(E-pz))
		pT = np.sqrt(px**2 + py**2)
		phi = np.arctan2(py, px)
		species = [('D+', 411), ('D0', 421), ('D*+', 413), ('D*0', 423)]
		
		Raa = get_Raa(pid=pid, pT=pT, y=y, ipT=ipT, yabs_cut=exp_Raa_ycut, species=species)
		vn = get_vn(pid=pid, phi=phi, pT=pT, y=y, ipT=ipT, yabs_cut=exp_vn_ycut, species=species)
		dndpt_gp = wo_urqmd_gp.create_group('dN_dpt')
		vn_gp = wo_urqmd_gp.create_group('vn')
		for (Dname, Did) in species:
			dn_i_dpt_gp = dndpt_gp.create_group(Dname)
			dn_i_dpt_gp.create_dataset('shape', data=Raa[Dname]['shape'], dtype=float_t)
			dn_i_dpt_gp.attrs.create('Ntot', Raa[Dname]['Ntot'], dtype=float_t)
			
			vn_i_gp = vn_gp.create_group(Dname)
			vn_i_gp.create_dataset('Qn', data=vn[Dname]['Qn'], dtype=complex_t)
			vn_i_gp.create_dataset('M', data=vn[Dname]['M'], dtype=float_t)

		# read final particle data	
		ID, charge, fmass, px, py, pz, y, eta, ipT, iw = (
			np.array(col, dtype=dtype) for (col, dtype) in
			zip(
				zip(*read_text_file('particles_out_{}.dat'.format(run_id))),
				(2*[int] + 8*[float])
			)
		)
		pT = np.sqrt(px**2+py**2)
		phi = np.arctan2(py, px)
		charged = (charge != 0)
		abs_eta = np.fabs(eta)
		abs_ID = np.abs(ID)
		midrapidity = (np.fabs(y) < .5)
		soft_index = np.array([iID not in HQ_id for iID in abs_ID])
		hard_index = np.array([iID in HQ_id for iID in abs_ID])

		# for soft particles
		soft_gp.attrs.create('dNch_deta',
			np.count_nonzero(charged & (abs_eta < .5) & soft_index) / nsamples)
		soft_gp.attrs.create('cen_mult',
			np.count_nonzero(charged & (abs_eta < .8) & soft_index) / nsamples)
		phi_alice = phi[charged & (abs_eta < .8) & (.2 < pT) & (pT < 5.)]
		soft_gp.attrs.create('M', phi_alice.size, dtype=int_t)
		soft_gp.create_dataset('Qn', data=np.array([np.exp(1j*n*phi_alice).sum() for n in range(1, 7)]), dtype=complex_t)
		
		# HF after Urqmd
		pid = abs_ID[hard_index]
		pT = pT[hard_index]
		y = y[hard_index]
		phi = phi[hard_index]
		ipT = ipT[hard_index]
		species = [('D+', 411), ('D0', 421), ('D*+', 10411)]
		Raa = get_Raa(pid=pid, pT=pT, y=y, ipT=ipT, yabs_cut=exp_Raa_ycut, species=species)
		vn = get_vn(pid=pid, phi=phi, pT=pT, y=y, ipT=ipT, yabs_cut=exp_vn_ycut, species=species)
		dndpt_gp = w_urqmd_gp.create_group('dN_dpt')
		vn_gp = w_urqmd_gp.create_group('vn')
		for (Dname, Did) in species:
			dn_i_dpt_gp = dndpt_gp.create_group(Dname)
			dn_i_dpt_gp.create_dataset('shape', data=Raa[Dname]['shape'], dtype=float_t)
			dn_i_dpt_gp.attrs.create('Ntot', Raa[Dname]['Ntot'], dtype=float_t)
			
			vn_i_gp = vn_gp.create_group(Dname)
			vn_i_gp.create_dataset('Qn', data=vn[Dname]['Qn'], dtype=complex_t)
			vn_i_gp.create_dataset('M', data=vn[Dname]['M'], dtype=float_t)
			
	fresult.close()


if __name__ == "__main__":
	main()
