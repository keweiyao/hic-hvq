#!/usr/bin/env python3

from itertools import chain
import sys
import subprocess
from multiprocessing import Pool, cpu_count

import numpy as np
import h5py

import freestream
import frzout

def EPS09_spectra(fname, nuA, nuB, hvq, sqrts):
	f = h5py.File(fname, 'r')
	ds = f['{}-{}-{}-{}'.format(nuA, nuB, hvq, sqrts)]
	M = ds.attrs['M']
	bmin, db, bmax = ds.attrs['bm-db-bM']
	ymax = ds['ymax'].value
	pT = ds['pT'].value
	pTmin, dpT = pT[0], pT[1]-pT[0]
	dX_b1_b2_dy_dpT = np.nan_to_num(ds['dX_b1_b2_dy_dpT2'].value)*pT
	Nb1, Nb2, Ny, NpT =  ds.attrs['dims']
	dny = 2./(Ny-1.)
	f.close()

	def interp(b1, b2, y, pT):
		mT = np.sqrt(pT**2 + M**2)
		if 2*mT >= sqrts:
			return 0.
		ymax = np.arccosh(sqrts/2./mT)
		if np.abs(y)>=ymax:
			return 0.
		ny = y/ymax
		xb1 = (b1-bmin)/db
		xb2 = (b2-bmin)/db
		xny = (ny+1.)/dny
		xpT = (pT - pTmin)/dpT
		ib1 = int(np.floor(xb1))
		ib2 = int(np.floor(xb2))
		iny = int(np.floor(xny))
		ipT = int(np.floor(xpT))
		ib1 = np.max([np.min([Nb1-2, ib1]), 0])
		ib2 = np.max([np.min([Nb2-2, ib2]), 0])
		iny = np.max([np.min([Ny-2, iny]), 0])
		ipT = np.max([np.min([NpT-2, ipT]), 0])
		rx1 = xb1 - ib1
		rx2 = xb2 - ib2
		rx3 = xny - iny
		rx4 = xpT - ipT
		result = 0.0
		ra1 = [1.-rx1, rx1]
		ra2 = [1.-rx2, rx2]
		ra3 = [1.-rx3, rx3]
		ra4 = [1.-rx4, rx4]
		for i1 in range(2):
			for i2 in range(2):
				for i3 in range(2):
					for i4 in range(2):
						result += dX_b1_b2_dy_dpT[ib1+i1, ib2+i2, \
													  iny+i3, ipT+i4] \
													*ra1[i1]*ra2[i2]*ra3[i3]*ra4[i4]
		return result
	interp = np.vectorize(interp)
	return interp

def nCTEQ_spectra(fname, nuA, nuB, hvq, sqrts):
	f = h5py.File(fname, 'r')
	ds = f['nCTEQ15np/{}-{}-{}-{}'.format(nuA, nuB, hvq, sqrts)]
	M = ds.attrs['M']
	ymax = ds['ymax'].value
	pT = ds['pT'].value
	pTmin, dpT = pT[0], pT[1]-pT[0]
	dX_dy_dpT = np.nan_to_num(ds['dX_dy_dpT2'].value)*pT
	Ny, NpT =  ds.attrs['dims']
	dny = 2./(Ny-1.)
	f.close()

	def interp(y, pT):
		mT = np.sqrt(pT**2 + M**2)
		if 2*mT >= sqrts:
			return 0.
		ymax = np.arccosh(sqrts/2./mT)
		if np.abs(y)>=ymax:
			return 0.
		ny = y/ymax
		xny = (ny+1.)/dny
		xpT = (pT - pTmin)/dpT
		iny = int(np.floor(xny))
		ipT = int(np.floor(xpT))
		iny = np.max([np.min([Ny-2, iny]), 0])
		ipT = np.max([np.min([NpT-2, ipT]), 0])
		rx3 = xny - iny
		rx4 = xpT - ipT
		result = 0.0
		ra3 = [1.-rx3, rx3]
		ra4 = [1.-rx4, rx4]
		for i3 in range(2):
			for i4 in range(2):
				result += dX_dy_dpT[iny+i3, ipT+i4] \
						*ra3[i3]*ra4[i4]
		return result
	interp = np.vectorize(interp)
	return interp			

def afterburner(Nstart, Nstop):
	for index in range(Nstart, Nstop):
		run_cmd('run_urqmd urqmd_input_{:03d} urqmd_output_{:03d}'.format(index, index))


def run_cmd(*args, **kwargs):
	"""
	Run a subprocess, concatenating argument strings together.

	"""
	print(*args, flush=True)  # flush stdout to retain output order
	subprocess.check_call(
		list(chain.from_iterable(a.split() for a in args)),
		**kwargs
	)


def read_text_file(filename):
	"""
	Read a text file into a nested list of bytes objects,
	skipping comment lines (#).

	"""
	with open(filename, 'rb') as f:
		return [l.split() for l in f if not l.startswith(b'#')]


def main():
	fresult = h5py.File('results.hdf5','a')
	# parse config file
	if len(sys.argv) >= 2:
		with open(sys.argv[1], 'r') as f:
			config = dict(
				(i.strip() for i in l.split('=', maxsplit=1))
				for l in f if l[0] != '#'
			)
		if len(sys.argv) == 3:
			run_id = int(sys.argv[2])
		else:	
			print("Hi")
			run_id = 0
	else:
		config = {}
	print ('==========',run_id, '=============')
	nevents = 1
	grid_step = 0.1
	grid_max = 15.05

	# run trento and yield initial entropy density arrays
	def initial_conditions(initial_file='initial.hdf'):
		run_cmd(
			'trento Pb Pb', str(nevents),
			'--grid-step {} --grid-max {}'.format(grid_step, grid_max),
			'--output', initial_file,
			config.get('trento_args', '')
		)
		with h5py.File(initial_file, 'r') as f:
			for dset in f.values():
				if dset.name[1:4] != 'TAB':
					yield [np.array(dset), np.array(f['TAB'+dset.name[-2:]])]

	#==================Hard pT bins and exp cuts=================================
	pTlow = 0.
	pThigh = 100.
	NpT = 100
	pTbins = np.linspace(pTlow, pThigh, NpT+1)
	pTmid = (pTbins[:-1] + pTbins[1:])/2.
	exp_name = config.get('collaboration', 'something else')
	sqrts = int(config.get('sqrts', '2760'))
	print ('exp : ', exp_name)
	print ('sqrts :', sqrts, " GeV")
	if exp_name == "CMS":
		print('use CMS cuts')
		exp_Raa_ycut = 1.0
		exp_vn_ycut = 1.0
		soft_pTrange = [0.3,3.0]
	elif exp_name == "ALICE":
		print('use ALICE cuts')
		exp_Raa_ycut = 0.5
		exp_vn_ycut = 0.8
		soft_pTrange = [0.15, 5.0]
	elif exp_name == "STAR":
		exp_Raa_ycut = 1.0
		exp_vn_ycut = 1.0
	else:
		print('use default cuts')
		exp_Raa_ycut = 2.0
		exp_vn_ycut = 2.0

	# read free streaming time and enable for time > epsilon
	tau_fs = float(config.get('tau_fs', 0))
	enable_fs = tau_fs > 1e-6

	# create sampler HRG object (to be reused for all events)
	Tswitch = float(config.get('Tswitch', .154))
	hrg = frzout.HRG(Tswitch, species='urqmd', res_width=True)
	eswitch = hrg.energy_density()

	# append switching energy density to vishnew arguments
	vishnew_args = [
		config.get('vishnew_args', ''),
		'initialuread=1 iein=0 t0={}'.format(tau_fs) if enable_fs else
		'initialuread=0 iein=1',
		'edec={}'.format(eswitch)
	]

	# species (name, ID) for identified particle observables
	species = [
		('pion', 211),
		('kaon', 321),
		('proton', 2212),
	]

	# Heavy quark species (name, ID)
	mass = float(config.get('mass', 1.3))
	HQ_species = [
		 ('D+', 411), 
		 ('D0', 421),
		 ('D*+', 10411),
		 ('D0*', 10421), 
		 ('Ds+', 431), 
		 ('Ds*+', 433)
	]
	HQ_id = [s[1] for s in HQ_species]	

	# fully specify numeric data types, including endianness and size, to
	# ensure consistency across all machines
	float_t = '<f8'
	int_t = '<i8'
	complex_t = '<c16'

	# run each event
	for ievent, ic in enumerate(initial_conditions()):
		event_gp = fresult.create_group('event_{}_{}'.format(run_id, ievent))
		soft_gp = event_gp.create_group('soft')
		hard_gp = event_gp.create_group('hard')
		quark_gp = hard_gp.create_group('quark')
		meson_gp = hard_gp.create_group('meson')

		soft_gp.attrs.create('initial_entropy', grid_step**2 * ic[0].sum())
		hard_gp.attrs.create('T_AB', grid_step**2 * ic[1].sum())
		hard_gp.attrs.create('pT_low', pTlow)
		hard_gp.attrs.create('pT_high', pThigh)
		hard_gp.attrs.create('pT_N', NpT)

		# ==================IC+freestream===========================
		if enable_fs:
			# free stream initial condition
			fs = freestream.FreeStreamer(ic[0], grid_max, tau_fs)

			e = fs.energy_density()
			e_above = e[e > eswitch].sum()
			soft_gp.attrs.create('mult_factor', e.sum()/e_above if e_above > 0 else 1)

			np.savetxt('ed.dat', e)
			for i in [1, 2]:
				np.savetxt('u{}.dat'.format(i), fs.flow_velocity(i))
			for ij in [(1, 1), (1, 2), (2, 2)]:
				np.savetxt(
					'pi{}{}.dat'.format(*ij), fs.shear_tensor(*ij))
		else:
			# skip free streaming, use initial condition as entropy density
			np.savetxt('sd.dat', ic[0])
		# ==================Vishnew===========================
		# hydro
		run_cmd('vishnew', *vishnew_args)
		# ==================Frzout Sampler===========================
		# read freeze-out surface data
		surface_data = np.array(
			read_text_file('surface.dat'),
			dtype=float
		)
		# end event if the surface is empty -- this occurs in ultra-peripheral
		# events where the initial condition doesn't exceed Tswitch
		if surface_data.size == 0:
			print('empty hypersurface')
			continue

		# unpack surface_data columns:
		#   0	1  2  3		 4		 5		 6	7
		#   tau  x  y  dsigma^t  dsigma^x  dsigma^y  v_x  v_y
		#   8	 9	 10	11	12	13	14	15
		#   pitt  pitx  pity  pixx  pixy  piyy  pizz  Pi
		x, sigma, v, _ = np.hsplit(surface_data, [3, 6, 8])
		pi = dict(zip(['xx', 'xy', 'yy'], surface_data.T[11:14]))
		Pi = surface_data.T[15]
		# create sampler surface object
		surface = frzout.Surface(x, sigma, v, pi=pi, Pi=Pi, ymax=3.)

		minsamples, maxsamples = 10, 100  # reasonable range for nsamples
		minparts = 20000  # min number of particles to sample
		nparts = 0  # for tracking total number of sampled particles

		# sample soft particles and write to file
		with open('particles_in.dat', 'w') as f:
			for nsamples in range(1, maxsamples + 1):
				parts = frzout.sample(surface, hrg)
				if parts.size == 0:
					continue
				nparts += parts.size
				print('#', parts.size, file=f)
				for p in parts:
					print(p['ID'], *chain(p['x'], p['p']), file=f)
				if nparts >= minparts and nsamples >= minsamples:
					break

		if nparts == 0:
			print('no particles produced')
			continue

		soft_gp.attrs.create('nsamples', nsamples, dtype=int_t)

		# ==================Heavy Flavor===========================
		run_cmd('run-hvq-events ./JetData.h5 ./initial.hdf {} {}'.format(sys.argv[1], run_id))

		# ==================Heavy + Soft --> UrQMD===========================
		# step 1: combine soft and hard particles and split into n-oversamples
		run_cmd('convert_format {} particles_in.dat h-meson-final-{}.dat'.format(nsamples, run_id, run_id))
		# step 2: split these n-oversamples into separate files
		subprocess.call('csplit --elide-empty-files --digits=3 --quiet --prefix=urqmd_input_ urqmd_input.dat "/UQMD/" "{*}" ', shell=True)
		# step 3: parallely run each oversamples:
		Nproc = np.min([cpu_count()-1 or 1, 10, nsamples])
		Nstep = np.floor(nsamples*1./Nproc).astype(int)
		Nstart = (np.array(range(Nproc))*Nstep).astype(int)
		Nstop = Nstart + Nstep
		Nstop[-1] = nsamples
		print("# start index", Nstart)
		print("# stop index", Nstop)
		with Pool(Nproc) as pool:
			pool.starmap(afterburner, zip(Nstart, Nstop))
		# step 4: combine all outputs together
		subprocess.call('cat urqmd_output_* > particles_out_{}.dat'.format(run_id), shell=True)

		# ==================Data Processing==================================

		# EPS09 spectra dependends on b1, b2, y, pT
		dN_EPS09 = EPS09_spectra("./hic-hvq/share/hvq/lhc/EPS09-spectra.hdf5",
							nuA='Pb', nuB='Pb', hvq='Charm', sqrts=sqrts)
		# nCTEQ spectra dependends only on y and pT
		dN_nCTEQ = nCTEQ_spectra("./hic-hvq/share/hvq/lhc/nCTEQ15np-spectra.hdf5",
							nuA='Pb', nuB='Pb', hvq='Charm', sqrts=sqrts)
		
		def p4_to_pT_and_y(px, py, pz, E):
			return np.sqrt(px**2+py**2), 0.5*np.log((E+pz)/(E-pz))
		def p4_to_pT_phi_and_y(px, py, pz, E):
			return np.sqrt(px**2+py**2), np.arctan2(py,px), 	\
				0.5*np.log((E+pz)/(E-pz))

		# ----Function to calculate Raa and v2-------------------------------
		def get_Raa(pid, pT, y, pT0, y0, s1, s2, yabs_cut, species):
			# calculate pT-spectra for each species
			Raa = {'EPS09': {}, 'nCTEQ': {}}
			for (Dname, Did) in species:
				cut = (np.abs(y) < yabs_cut) & (pid == Did)
				# First do it for EPS09
				HQpT, HQw = pT[cut], dN_EPS09(s1[cut], s2[cut], y0[cut], pT0[cut])

				Hist, BinEdges = np.histogram(HQpT, bins=NpT, 
											range=[pTlow, pThigh], 
											normed=True, weights=HQw)
				Raa['EPS09'].update({Dname : {'shape' : Hist, 'Ntot' : HQw.sum()} })
				# Then, do it for nCTEQ				
				HQpT, HQw = pT[cut], dN_nCTEQ(y0[cut], pT0[cut])
				Hist, BinEdges = np.histogram(HQpT, bins=NpT, 
											range=[pTlow, pThigh], 
											normed=True, weights=HQw)
				Raa['nCTEQ'].update({Dname : {'shape' : Hist, 'Ntot' : HQw.sum()} })
			return Raa

		def get_vn(pid, pT, phi, y, pT0, y0, s1, s2, yabs_cut, species):
			# calculate Qn
			vn = {'EPS09': {}, 'nCTEQ': {}}
			for (Dname, Did) in species:
				cut = (np.abs(y) < yabs_cut) & (pid == Did)
				# First do it for EPS09
				HQphi, HQpT, HQw = phi[cut], pT[cut], \
								   dN_EPS09(s1[cut], s2[cut], y0[cut], pT0[cut])
				Qn_array = np.zeros([NpT, 3], dtype=complex_t)
				M_array = np.zeros(NpT)
				for icut, [pl, ph] in enumerate(zip(pTbins[:-1], pTbins[1:])):
					pTcut = (pl < HQpT) & (HQpT <= ph)
					diff_phi = HQphi[pTcut]
					diff_w = HQw[pTcut]
					Qn_array[icut] = np.array([(np.exp(1j*n*diff_phi)*diff_w).sum() for n in range(1, 4)], dtype=complex_t)
					M_array[icut] = diff_w.sum()
				vn['EPS09'].update({Dname : {'Qn' : Qn_array, 'M' : M_array} })

				# Second do it for nCTEQ
				HQphi, HQpT, HQw = phi[cut], pT[cut], \
								   dN_nCTEQ(y0[cut], pT0[cut])
				Qn_array = np.zeros([NpT, 3], dtype=complex_t)
				M_array = np.zeros(NpT)
				for icut, [pl, ph] in enumerate(zip(pTbins[:-1], pTbins[1:])):
					pTcut = (pl < HQpT) & (HQpT <= ph)
					diff_phi = HQphi[pTcut]
					diff_w = HQw[pTcut]
					Qn_array[icut] = np.array([(np.exp(1j*n*diff_phi)*diff_w).sum() for n in range(1, 4)], dtype=complex_t)
					M_array[icut] = diff_w.sum()
				vn['nCTEQ'].update({Dname : {'Qn' : Qn_array, 'M' : M_array} })
			return vn
		

		# start from here
		def calculate_and_save_HQ_obs(data_group, 
									  pid, pT, phi, y, 
									  pT0, y0, s1, s2,
									  Raa_ycut, vn_ycut, species):
			data_group.create_group('EPS09')
			data_group.create_group('nCTEQ')
			Raa = get_Raa(pid=pid, pT=pT, y=y, 
					  	  pT0=pT0, y0=y0, s1=s1, s2=s2,
						  yabs_cut=Raa_ycut, species=species)
			vn = get_vn(pid=pid, pT=pT, phi=phi, y=y, 
						pT0=pT0, y0=y0, s1=s1, s2=s2,
						yabs_cut=vn_ycut, species=species)
			for ref in ['EPS09', 'nCTEQ']:
				dndpt_gp = data_group[ref].create_group('dN_dpt')
				vn_gp = data_group[ref].create_group('vn')
				for (pname, pid) in species:
					dn_i_dpt_gp = dndpt_gp.create_group(pname)
					dn_i_dpt_gp.create_dataset('shape', 
								data=Raa[ref][pname]['shape'], dtype=float_t)
					dn_i_dpt_gp.attrs.create('Ntot',
								Raa[ref][pname]['Ntot'], dtype=float_t)
			
					vn_i_gp = vn_gp.create_group(pname)
					vn_i_gp.create_dataset('Qn', 
								data=vn[ref][pname]['Qn'], dtype=complex_t)
					vn_i_gp.create_dataset('M', 
								data=vn[ref][pname]['M'], dtype=float_t)

		# read final particle data	
		ID, charge, fmass, px, py, pz, y, eta, pT0, y0, s1, s2 = (
			np.array(col, dtype=dtype) for (col, dtype) in
			zip(
				zip(*read_text_file('particles_out_{}.dat'.format(run_id))),
				(2*[int] + 10*[float])
			)
		)
		pT = np.sqrt(px**2+py**2)
		phi = np.arctan2(py, px)
		charged = (charge != 0)
		abs_eta = np.fabs(eta)
		abs_ID = np.abs(ID)
		soft_index = np.array([iID not in HQ_id for iID in abs_ID])
		hard_index = np.array([iID in HQ_id for iID in abs_ID])

		#============for soft particles======================
		soft_gp.attrs.create('dNch_deta',
			np.count_nonzero(charged & (abs_eta < .5) & soft_index) / nsamples)
		soft_gp.attrs.create('cen_mult',
			np.count_nonzero(charged & (abs_eta < .8) & soft_index) / nsamples)
		phi_soft = phi[charged & (abs_eta < exp_vn_ycut)  & (soft_pTrange[0] < pT) & soft_index]
		soft_gp.attrs.create('M', phi_soft.shape[0], dtype=int_t)
		soft_gp.create_dataset('Qn', data=np.array([np.exp(1j*n*phi_soft).sum() for n in range(1, 7)]), dtype=complex_t)


		#===========For heavy particles======================
		# HF after Urqmd
		pid = abs_ID[hard_index]
		pT = pT[hard_index]
		y = y[hard_index]
		phi = phi[hard_index]
		pT0 = pT0[hard_index]
		y0 = y0[hard_index]	
		s1 = s1[hard_index]
		s2 = s2[hard_index]
		#print(np.max(s1), np.min(s1), np.max(s2), np.min(s2))
		species = [('D+', 411), ('D0', 421), ('D*+', 10411)]
		calculate_and_save_HQ_obs(meson_gp, 
								  pid, pT, phi, y, 
								  pT0, y0, s1, s2,
								  exp_Raa_ycut, exp_vn_ycut, species)


		#---------For comparison----------------
		# For final charm quark
		fquark = h5py.File('./HeavyFlavorResult.hdf5', 'r')
		pT0, y0 = p4_to_pT_and_y(*fquark['quark-p0-{}'.format(run_id)].value.T)
		pT, phi, y = p4_to_pT_phi_and_y(
								*fquark['quark-p-{}'.format(run_id)].value.T)
		s1, s2 = fquark['quark-s1-s2-{}'.format(run_id)].value.T
		pid = fquark['quark-pid-{}'.format(run_id)].value
		fquark.close()
		species = [('charm', 4)]
		calculate_and_save_HQ_obs(quark_gp,
								  pid, pT, phi, y, 
								  pT0, y0, s1, s2,
								  10., 10., species)

	fresult.close()


if __name__ == "__main__":
	main()

