#!/bin/bash

# gather system data
uname -nr

# read arguments
inputfile=$1
desturl=$2
eventperjob=4

# load necessary modules
source /cvmfs/oasis.opensciencegrid.org/osg/modules/lmod/current/init/bash
module purge
module load python/3.5.2 all-pkgs gcc/6.2.0 boost/1.62.0-cxx11 gsl/2.3
module load hdf5/1.8.20-cxx11
module list
# unpack package
export pkgname='hic-hvq'
tar xzf $pkgname.tar.gz
#tar xzf $inputfile --strip-components 2
# set environment variables
prefix="$(pwd)/$pkgname"
export PATH="$prefix/bin:$PATH"
export XDG_DATA_HOME="$prefix/share"
export PYTHONPATH="$(echo $prefix/lib/python*/site-packages)"
#:"$(echo $prefix/lib64/python*/site-packages)"
echo $PYTHONPATH

if [[ -f HeavyFlavorResult.hdf5 ]]; then
    rm HeavyFlavorResult.hdf5
fi
if [[ -f results.hdf5 ]]; then
    rm results.hdf5
fi

# go!
for i in `seq 1 $eventperjob`; do
  # first clean the info from last run
  if [[ -f initial.hdf ]]; then
    rm initial.hdf
  fi
  if [[ -f JetData.h5 ]]; then
    rm JetData.h5
  fi
  if [[ -f FreeStream.h5 ]]; then
    rm FreeStream.h5
  fi

  # run events
  run-events $inputfile $i || exit 1
done

# transfer results
# try to be fault-tolerant
globus() {
     globus-url-copy \
    -verbose -create-dest -restart -stall-timeout 30 $@ \
    results.hdf5 $desturl/results.hdf5   
}

for i in {1..5}; do
  globus && break
  sleep 5 && false
done || \
  globus -no-data-channel-authentication -no-third-party-transfers
